# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-13221）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
gamma='scale' in SVC
I believe that setting `gamma='scale'` in `SVC` is not meeting its intended purpose of being invariant to the scale of `X`. Currently, `gamma` is set to `1 / (n_features * X.std())`. However, I believe it should be `1 / (n_features * X.var())`. 

Rationale: if you scale `X` by 10 you need to scale `gamma` by 1/100, not 1/10, to achieve the same results. See the definition of the RBF kernel [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.rbf_kernel.html): the "units" of `gamma` are 1/x^2, not 1/x. 

I also tested this empirically: scaling `X` by 10 and scaling `gamma` by 1/100 gives the same result as the original, whereas scaling `X` by 10 and scaling `gamma` by 1/10 gives a different result. Here is some code:

```python
import numpy as np
from sklearn.svm import SVC

X = np.random.rand(100,10)
y = np.random.choice(2,size=100)

svm = SVC(gamma=1)
svm.fit(X,y)
print(svm.decision_function(X[:5]))

# scale X by 10, gamma by 1/100
svm = SVC(gamma=0.01)
svm.fit(10*X,y)
print(svm.decision_function(10*X[:5])) # prints same result

# scale X by 10, gamma by 1/10
svm = SVC(gamma=0.1)
svm.fit(10*X,y)
print(svm.decision_function(10*X[:5])) # prints different result
```

Note that `gamma='scale'` will become the default setting for `gamma` in version 0.22.

Related: #8361, #10331 


## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py
--- a/sklearn/model_selection/tests/test_search.py
+++ b/sklearn/model_selection/tests/test_search.py
@@ -1710,19 +1710,23 @@ def test_deprecated_grid_search_iid():
     depr_message = ("The default of the `iid` parameter will change from True "
                     "to False in version 0.22")
     X, y = make_blobs(n_samples=54, random_state=0, centers=2)
-    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=3)
+    grid = GridSearchCV(SVC(gamma='scale', random_state=0),
+                        param_grid={'C': [10]}, cv=3)
     # no warning with equally sized test sets
     assert_no_warnings(grid.fit, X, y)
 
-    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=5)
+    grid = GridSearchCV(SVC(gamma='scale', random_state=0),
+                        param_grid={'C': [10]}, cv=5)
     # warning because 54 % 5 != 0
     assert_warns_message(DeprecationWarning, depr_message, grid.fit, X, y)
 
-    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=2)
+    grid = GridSearchCV(SVC(gamma='scale', random_state=0),
+                        param_grid={'C': [10]}, cv=2)
     # warning because stratification into two classes and 27 % 2 != 0
     assert_warns_message(DeprecationWarning, depr_message, grid.fit, X, y)
 
-    grid = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1]}, cv=KFold(2))
+    grid = GridSearchCV(SVC(gamma='scale', random_state=0),
+                        param_grid={'C': [10]}, cv=KFold(2))
     # no warning because no stratification and 54 % 2 == 0
     assert_no_warnings(grid.fit, X, y)
 
diff --git a/sklearn/svm/tests/test_sparse.py b/sklearn/svm/tests/test_sparse.py
--- a/sklearn/svm/tests/test_sparse.py
+++ b/sklearn/svm/tests/test_sparse.py
@@ -87,9 +87,9 @@ def test_svc():
     kernels = ["linear", "poly", "rbf", "sigmoid"]
     for dataset in datasets:
         for kernel in kernels:
-            clf = svm.SVC(gamma='scale', kernel=kernel, probability=True,
+            clf = svm.SVC(gamma=1, kernel=kernel, probability=True,
                           random_state=0, decision_function_shape='ovo')
-            sp_clf = svm.SVC(gamma='scale', kernel=kernel, probability=True,
+            sp_clf = svm.SVC(gamma=1, kernel=kernel, probability=True,
                              random_state=0, decision_function_shape='ovo')
             check_svm_model_equal(clf, sp_clf, *dataset)
 
@@ -293,8 +293,8 @@ def test_sparse_oneclasssvm(datasets_index, kernel):
                 [X_blobs[:80], None, X_blobs[80:]],
                 [iris.data, None, iris.data]]
     dataset = datasets[datasets_index]
-    clf = svm.OneClassSVM(gamma='scale', kernel=kernel)
-    sp_clf = svm.OneClassSVM(gamma='scale', kernel=kernel)
+    clf = svm.OneClassSVM(gamma=1, kernel=kernel)
+    sp_clf = svm.OneClassSVM(gamma=1, kernel=kernel)
     check_svm_model_equal(clf, sp_clf, *dataset)
 
 
diff --git a/sklearn/svm/tests/test_svm.py b/sklearn/svm/tests/test_svm.py
--- a/sklearn/svm/tests/test_svm.py
+++ b/sklearn/svm/tests/test_svm.py
@@ -243,11 +243,11 @@ def test_oneclass():
     clf.fit(X)
     pred = clf.predict(T)
 
-    assert_array_equal(pred, [-1, -1, -1])
+    assert_array_equal(pred, [1, -1, -1])
     assert_equal(pred.dtype, np.dtype('intp'))
-    assert_array_almost_equal(clf.intercept_, [-1.117], decimal=3)
+    assert_array_almost_equal(clf.intercept_, [-1.218], decimal=3)
     assert_array_almost_equal(clf.dual_coef_,
-                              [[0.681, 0.139, 0.68, 0.14, 0.68, 0.68]],
+                              [[0.750, 0.750, 0.750, 0.750]],
                               decimal=3)
     assert_raises(AttributeError, lambda: clf.coef_)
 
@@ -1003,9 +1003,9 @@ def test_gamma_scale():
 
     clf = svm.SVC(gamma='scale')
     assert_no_warnings(clf.fit, X, y)
-    assert_equal(clf._gamma, 2.)
+    assert_almost_equal(clf._gamma, 4)
 
-    # X_std ~= 1 shouldn't raise warning, for when
+    # X_var ~= 1 shouldn't raise warning, for when
     # gamma is not explicitly set.
     X, y = [[1, 2], [3, 2 * np.sqrt(6) / 3 + 2]], [0, 1]
     assert_no_warnings(clf.fit, X, y)