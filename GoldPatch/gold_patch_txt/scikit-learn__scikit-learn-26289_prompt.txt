# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-26289）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
sklearn.tree.export_text failing when feature_names supplied
folks, I'm not sure why this works for
```py
import sklearn.tree
print(my_feature_names)
['0' '0 trump' '0 trump versus' ... 'zur' 'zur ckhalten' 'zur ckhalten muss']

tree.export_graphviz(clf, out_file=None, max_depth=4, feature_names=my_feature_names)
```
but not for 

```py
import sklearn.tree
print(my_feature_names)
['0' '0 trump' '0 trump versus' ... 'zur' 'zur ckhalten' 'zur ckhalten muss']

tree.export_text(clf, max_depth=4, feature_names=my_feature_names)

Traceback (most recent call last):
  File "./sample-python-projects/machine-learning/HW1_Q2a.py", line 72, in <module>
    print(tree.export_text(clf, max_depth=4, feature_names=my_feature_names))
  File "C:\Users\sam\python\lib\site-packages\sklearn\tree\_export.py", line 1016, in export_text
    if feature_names:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
```

Can anyone help?


## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/tree/tests/test_export.py b/sklearn/tree/tests/test_export.py
--- a/sklearn/tree/tests/test_export.py
+++ b/sklearn/tree/tests/test_export.py
@@ -4,6 +4,7 @@
 from re import finditer, search
 from textwrap import dedent
 
+import numpy as np
 from numpy.random import RandomState
 import pytest
 
@@ -48,48 +49,6 @@ def test_graphviz_toy():
 
     assert contents1 == contents2
 
-    # Test with feature_names
-    contents1 = export_graphviz(
-        clf, feature_names=["feature0", "feature1"], out_file=None
-    )
-    contents2 = (
-        "digraph Tree {\n"
-        'node [shape=box, fontname="helvetica"] ;\n'
-        'edge [fontname="helvetica"] ;\n'
-        '0 [label="feature0 <= 0.0\\ngini = 0.5\\nsamples = 6\\n'
-        'value = [3, 3]"] ;\n'
-        '1 [label="gini = 0.0\\nsamples = 3\\nvalue = [3, 0]"] ;\n'
-        "0 -> 1 [labeldistance=2.5, labelangle=45, "
-        'headlabel="True"] ;\n'
-        '2 [label="gini = 0.0\\nsamples = 3\\nvalue = [0, 3]"] ;\n'
-        "0 -> 2 [labeldistance=2.5, labelangle=-45, "
-        'headlabel="False"] ;\n'
-        "}"
-    )
-
-    assert contents1 == contents2
-
-    # Test with class_names
-    contents1 = export_graphviz(clf, class_names=["yes", "no"], out_file=None)
-    contents2 = (
-        "digraph Tree {\n"
-        'node [shape=box, fontname="helvetica"] ;\n'
-        'edge [fontname="helvetica"] ;\n'
-        '0 [label="x[0] <= 0.0\\ngini = 0.5\\nsamples = 6\\n'
-        'value = [3, 3]\\nclass = yes"] ;\n'
-        '1 [label="gini = 0.0\\nsamples = 3\\nvalue = [3, 0]\\n'
-        'class = yes"] ;\n'
-        "0 -> 1 [labeldistance=2.5, labelangle=45, "
-        'headlabel="True"] ;\n'
-        '2 [label="gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\\n'
-        'class = no"] ;\n'
-        "0 -> 2 [labeldistance=2.5, labelangle=-45, "
-        'headlabel="False"] ;\n'
-        "}"
-    )
-
-    assert contents1 == contents2
-
     # Test plot_options
     contents1 = export_graphviz(
         clf,
@@ -249,6 +208,60 @@ def test_graphviz_toy():
     )
 
 
+@pytest.mark.parametrize("constructor", [list, np.array])
+def test_graphviz_feature_class_names_array_support(constructor):
+    # Check that export_graphviz treats feature names
+    # and class names correctly and supports arrays
+    clf = DecisionTreeClassifier(
+        max_depth=3, min_samples_split=2, criterion="gini", random_state=2
+    )
+    clf.fit(X, y)
+
+    # Test with feature_names
+    contents1 = export_graphviz(
+        clf, feature_names=constructor(["feature0", "feature1"]), out_file=None
+    )
+    contents2 = (
+        "digraph Tree {\n"
+        'node [shape=box, fontname="helvetica"] ;\n'
+        'edge [fontname="helvetica"] ;\n'
+        '0 [label="feature0 <= 0.0\\ngini = 0.5\\nsamples = 6\\n'
+        'value = [3, 3]"] ;\n'
+        '1 [label="gini = 0.0\\nsamples = 3\\nvalue = [3, 0]"] ;\n'
+        "0 -> 1 [labeldistance=2.5, labelangle=45, "
+        'headlabel="True"] ;\n'
+        '2 [label="gini = 0.0\\nsamples = 3\\nvalue = [0, 3]"] ;\n'
+        "0 -> 2 [labeldistance=2.5, labelangle=-45, "
+        'headlabel="False"] ;\n'
+        "}"
+    )
+
+    assert contents1 == contents2
+
+    # Test with class_names
+    contents1 = export_graphviz(
+        clf, class_names=constructor(["yes", "no"]), out_file=None
+    )
+    contents2 = (
+        "digraph Tree {\n"
+        'node [shape=box, fontname="helvetica"] ;\n'
+        'edge [fontname="helvetica"] ;\n'
+        '0 [label="x[0] <= 0.0\\ngini = 0.5\\nsamples = 6\\n'
+        'value = [3, 3]\\nclass = yes"] ;\n'
+        '1 [label="gini = 0.0\\nsamples = 3\\nvalue = [3, 0]\\n'
+        'class = yes"] ;\n'
+        "0 -> 1 [labeldistance=2.5, labelangle=45, "
+        'headlabel="True"] ;\n'
+        '2 [label="gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\\n'
+        'class = no"] ;\n'
+        "0 -> 2 [labeldistance=2.5, labelangle=-45, "
+        'headlabel="False"] ;\n'
+        "}"
+    )
+
+    assert contents1 == contents2
+
+
 def test_graphviz_errors():
     # Check for errors of export_graphviz
     clf = DecisionTreeClassifier(max_depth=3, min_samples_split=2)
@@ -352,7 +365,7 @@ def test_export_text_errors():
     with pytest.raises(ValueError, match=err_msg):
         export_text(clf, feature_names=["a"])
     err_msg = (
-        "When `class_names` is a list, it should contain as"
+        "When `class_names` is an array, it should contain as"
         " many items as `decision_tree.classes_`. Got 1 while"
         " the tree was fitted with 2 classes."
     )
@@ -377,22 +390,6 @@ def test_export_text():
     # testing that the rest of the tree is truncated
     assert export_text(clf, max_depth=10) == expected_report
 
-    expected_report = dedent("""
-    |--- b <= 0.00
-    |   |--- class: -1
-    |--- b >  0.00
-    |   |--- class: 1
-    """).lstrip()
-    assert export_text(clf, feature_names=["a", "b"]) == expected_report
-
-    expected_report = dedent("""
-    |--- feature_1 <= 0.00
-    |   |--- class: cat
-    |--- feature_1 >  0.00
-    |   |--- class: dog
-    """).lstrip()
-    assert export_text(clf, class_names=["cat", "dog"]) == expected_report
-
     expected_report = dedent("""
     |--- feature_1 <= 0.00
     |   |--- weights: [3.00, 0.00] class: -1
@@ -453,6 +450,30 @@ def test_export_text():
     )
 
 
+@pytest.mark.parametrize("constructor", [list, np.array])
+def test_export_text_feature_class_names_array_support(constructor):
+    # Check that export_graphviz treats feature names
+    # and class names correctly and supports arrays
+    clf = DecisionTreeClassifier(max_depth=2, random_state=0)
+    clf.fit(X, y)
+
+    expected_report = dedent("""
+    |--- b <= 0.00
+    |   |--- class: -1
+    |--- b >  0.00
+    |   |--- class: 1
+    """).lstrip()
+    assert export_text(clf, feature_names=constructor(["a", "b"])) == expected_report
+
+    expected_report = dedent("""
+    |--- feature_1 <= 0.00
+    |   |--- class: cat
+    |--- feature_1 >  0.00
+    |   |--- class: dog
+    """).lstrip()
+    assert export_text(clf, class_names=constructor(["cat", "dog"])) == expected_report
+
+
 def test_plot_tree_entropy(pyplot):
     # mostly smoke tests
     # Check correctness of export_graphviz for criterion = entropy