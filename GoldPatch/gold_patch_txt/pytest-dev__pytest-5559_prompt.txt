# 修复代码生成提示词（实例ID：pytest-dev__pytest-5559）
## 代码仓库
pytest-dev/pytest

## 原始问题描述
pytest stepwise doesn't work with xfail strict failures
```
graingert@onomastic:~/projects/foo$ cat tests/test_foo.py 
import pytest


@pytest.mark.xfail(reason="pass")
def test_a():
    pass


@pytest.mark.xfail(reason="pass")
def test_b():
    pass
graingert@onomastic:~/projects/foo$ cat tests/pytest.ini 
[pytest]
addopts = --strict
xfail_strict=true
graingert@onomastic:~/projects/foo$ pytest --sw tests/
================================ test session starts ================================
platform linux -- Python 3.7.3, pytest-5.0.0, py-1.8.0, pluggy-0.12.0
rootdir: /home/graingert/projects/foo/tests, inifile: pytest.ini
collected 2 items                                                                   
stepwise: no previously failed tests, not skipping.

tests/test_foo.py FF                                                          [100%]

===================================== FAILURES ======================================
______________________________________ test_a _______________________________________
[XPASS(strict)] pass
______________________________________ test_b _______________________________________
[XPASS(strict)] pass
============================= 2 failed in 0.01 seconds ==============================
```
recommended pytest-runner in setup_requires means packages fail to install often
The recommendation to add `pytest-runner` to `setup_requires` means that all users of that package end up with an unnecessary pytest-runner package installed. This is bad because it bypasses pip hashes and [`--trusted-host`](https://github.com/pypa/pip/issues/4156)

https://docs.pytest.org/en/latest/goodpractices.html#integrating-with-setuptools-python-setup-py-test-pytest-runner

https://github.com/MechanicalSoup/MechanicalSoup/pull/224
https://github.com/rxcomm/pyaxo/issues/26
https://github.com/jpadilla/pyjwt/issues/179


## 参考黄金补丁（正确的修复方案）
diff --git a/doc/en/example/nonpython/test_simple.yml b/doc/en/example/nonpython/test_simple.yaml
similarity index 75%
rename from doc/en/example/nonpython/test_simple.yml
rename to doc/en/example/nonpython/test_simple.yaml
--- a/doc/en/example/nonpython/test_simple.yml
+++ b/doc/en/example/nonpython/test_simple.yaml
@@ -1,4 +1,4 @@
-# test_simple.yml
+# test_simple.yaml
 ok:
     sub1: sub1
 
diff --git a/testing/python/raises.py b/testing/python/raises.py
--- a/testing/python/raises.py
+++ b/testing/python/raises.py
@@ -220,13 +220,20 @@ def test_raises_match(self):
             int("asdf")
 
         msg = "with base 16"
-        expr = r"Pattern '{}' not found in 'invalid literal for int\(\) with base 10: 'asdf''".format(
+        expr = r"Pattern '{}' not found in \"invalid literal for int\(\) with base 10: 'asdf'\"".format(
             msg
         )
         with pytest.raises(AssertionError, match=expr):
             with pytest.raises(ValueError, match=msg):
                 int("asdf", base=10)
 
+    def test_match_failure_string_quoting(self):
+        with pytest.raises(AssertionError) as excinfo:
+            with pytest.raises(AssertionError, match="'foo"):
+                raise AssertionError("'bar")
+        msg, = excinfo.value.args
+        assert msg == 'Pattern "\'foo" not found in "\'bar"'
+
     def test_raises_match_wrong_type(self):
         """Raising an exception with the wrong type and match= given.
 
diff --git a/testing/test_stepwise.py b/testing/test_stepwise.py
--- a/testing/test_stepwise.py
+++ b/testing/test_stepwise.py
@@ -165,3 +165,56 @@ def test_stop_on_collection_errors(broken_testdir, broken_first):
         files.reverse()
     result = broken_testdir.runpytest("-v", "--strict-markers", "--stepwise", *files)
     result.stdout.fnmatch_lines("*errors during collection*")
+
+
+def test_xfail_handling(testdir):
+    """Ensure normal xfail is ignored, and strict xfail interrupts the session in sw mode
+
+    (#5547)
+    """
+    contents = """
+        import pytest
+        def test_a(): pass
+
+        @pytest.mark.xfail(strict={strict})
+        def test_b(): assert {assert_value}
+
+        def test_c(): pass
+        def test_d(): pass
+    """
+    testdir.makepyfile(contents.format(assert_value="0", strict="False"))
+    result = testdir.runpytest("--sw", "-v")
+    result.stdout.fnmatch_lines(
+        [
+            "*::test_a PASSED *",
+            "*::test_b XFAIL *",
+            "*::test_c PASSED *",
+            "*::test_d PASSED *",
+            "* 3 passed, 1 xfailed in *",
+        ]
+    )
+
+    testdir.makepyfile(contents.format(assert_value="1", strict="True"))
+    result = testdir.runpytest("--sw", "-v")
+    result.stdout.fnmatch_lines(
+        [
+            "*::test_a PASSED *",
+            "*::test_b FAILED *",
+            "* Interrupted*",
+            "* 1 failed, 1 passed in *",
+        ]
+    )
+
+    # because we are writing to the same file, mtime might not be affected enough to
+    # invalidate the cache, making this next run flaky
+    testdir.tmpdir.join("__pycache__").remove()
+    testdir.makepyfile(contents.format(assert_value="0", strict="True"))
+    result = testdir.runpytest("--sw", "-v")
+    result.stdout.fnmatch_lines(
+        [
+            "*::test_b XFAIL *",
+            "*::test_c PASSED *",
+            "*::test_d PASSED *",
+            "* 2 passed, 1 deselected, 1 xfailed in *",
+        ]
+    )