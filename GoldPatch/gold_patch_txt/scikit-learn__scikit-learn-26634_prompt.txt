# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-26634）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
NMF fit transform without updating H should not require the user to input "n_components"
The `_fit_transform` function of the `_nmf` module has the option to set `update_H=False`, where the H matrix is left constant. the private method `_fit_transform` is called by the exposed `non_negative_factorization` function.
In a scenario I've encountered, the user provides the H matrix, meaning the number of components is known a-prior, and there is no reason for the algorithm to run the lines
```
        if self._n_components is None:
            self._n_components = X.shape[1]
``` 
and raise an error later in the `_check_w_h`


https://github.com/scikit-learn/scikit-learn/blob/f5ec34e0f76277ba6d0a77d3033db0af83899b64/sklearn/decomposition/_nmf.py#LL1188C19-L1188C19


## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/decomposition/tests/test_nmf.py b/sklearn/decomposition/tests/test_nmf.py
--- a/sklearn/decomposition/tests/test_nmf.py
+++ b/sklearn/decomposition/tests/test_nmf.py
@@ -45,9 +45,11 @@ def test_initialize_nn_output():
         assert not ((W < 0).any() or (H < 0).any())
 
 
+# TODO(1.6): remove the warning filter for `n_components`
 @pytest.mark.filterwarnings(
     r"ignore:The multiplicative update \('mu'\) solver cannot update zeros present in"
-    r" the initialization"
+    r" the initialization",
+    "ignore:The default value of `n_components` will change",
 )
 def test_parameter_checking():
     # Here we only check for invalid parameter values that are not already
@@ -267,6 +269,8 @@ def test_nmf_inverse_transform(solver):
     assert_array_almost_equal(A, A_new, decimal=2)
 
 
+# TODO(1.6): remove the warning filter
+@pytest.mark.filterwarnings("ignore:The default value of `n_components` will change")
 def test_mbnmf_inverse_transform():
     # Test that MiniBatchNMF.transform followed by MiniBatchNMF.inverse_transform
     # is close to the identity
@@ -344,6 +348,8 @@ def test_nmf_sparse_transform(Estimator, solver):
     assert_allclose(A_fit_tr, A_tr, atol=1e-1)
 
 
+# TODO(1.6): remove the warning filter
+@pytest.mark.filterwarnings("ignore:The default value of `n_components` will change")
 @pytest.mark.parametrize("init", ["random", "nndsvd"])
 @pytest.mark.parametrize("solver", ("cd", "mu"))
 @pytest.mark.parametrize("alpha_W", (0.0, 1.0))
@@ -610,6 +616,8 @@ def _assert_nmf_no_nan(X, beta_loss):
         _assert_nmf_no_nan(X_csr, beta_loss)
 
 
+# TODO(1.6): remove the warning filter
+@pytest.mark.filterwarnings("ignore:The default value of `n_components` will change")
 @pytest.mark.parametrize("beta_loss", [-0.5, 0.0])
 def test_minibatch_nmf_negative_beta_loss(beta_loss):
     """Check that an error is raised if beta_loss < 0 and X contains zeros."""
@@ -766,6 +774,8 @@ def test_nmf_underflow():
     assert_almost_equal(res, ref)
 
 
+# TODO(1.6): remove the warning filter
+@pytest.mark.filterwarnings("ignore:The default value of `n_components` will change")
 @pytest.mark.parametrize(
     "dtype_in, dtype_out",
     [
@@ -784,13 +794,21 @@ def test_nmf_dtype_match(Estimator, solver, dtype_in, dtype_out):
     X = np.random.RandomState(0).randn(20, 15).astype(dtype_in, copy=False)
     np.abs(X, out=X)
 
-    nmf = Estimator(alpha_W=1.0, alpha_H=1.0, tol=1e-2, random_state=0, **solver)
+    nmf = Estimator(
+        alpha_W=1.0,
+        alpha_H=1.0,
+        tol=1e-2,
+        random_state=0,
+        **solver,
+    )
 
     assert nmf.fit(X).transform(X).dtype == dtype_out
     assert nmf.fit_transform(X).dtype == dtype_out
     assert nmf.components_.dtype == dtype_out
 
 
+# TODO(1.6): remove the warning filter
+@pytest.mark.filterwarnings("ignore:The default value of `n_components` will change")
 @pytest.mark.parametrize(
     ["Estimator", "solver"],
     [[NMF, {"solver": "cd"}], [NMF, {"solver": "mu"}], [MiniBatchNMF, {}]],
@@ -807,6 +825,8 @@ def test_nmf_float32_float64_consistency(Estimator, solver):
     assert_allclose(W32, W64, atol=1e-5)
 
 
+# TODO(1.6): remove the warning filter
+@pytest.mark.filterwarnings("ignore:The default value of `n_components` will change")
 @pytest.mark.parametrize("Estimator", [NMF, MiniBatchNMF])
 def test_nmf_custom_init_dtype_error(Estimator):
     # Check that an error is raise if custom H and/or W don't have the same
@@ -896,6 +916,8 @@ def test_feature_names_out():
     assert_array_equal([f"nmf{i}" for i in range(3)], names)
 
 
+# TODO(1.6): remove the warning filter
+@pytest.mark.filterwarnings("ignore:The default value of `n_components` will change")
 def test_minibatch_nmf_verbose():
     # Check verbose mode of MiniBatchNMF for better coverage.
     A = np.random.RandomState(0).random_sample((100, 10))
@@ -932,3 +954,106 @@ def test_NMF_inverse_transform_W_deprecation():
 
     with pytest.warns(FutureWarning, match="Input argument `W` was renamed to `Xt`"):
         est.inverse_transform(W=Xt)
+
+
+@pytest.mark.parametrize("Estimator", [NMF, MiniBatchNMF])
+def test_nmf_n_components_auto(Estimator):
+    # Check that n_components is correctly inferred
+    # from the provided custom initialization.
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((6, 5))
+    W = rng.random_sample((6, 2))
+    H = rng.random_sample((2, 5))
+    est = Estimator(
+        n_components="auto",
+        init="custom",
+        random_state=0,
+        tol=1e-6,
+    )
+    est.fit_transform(X, W=W, H=H)
+    assert est._n_components == H.shape[0]
+
+
+def test_nmf_non_negative_factorization_n_components_auto():
+    # Check that n_components is correctly inferred from the provided
+    # custom initialization.
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((6, 5))
+    W_init = rng.random_sample((6, 2))
+    H_init = rng.random_sample((2, 5))
+    W, H, _ = non_negative_factorization(
+        X, W=W_init, H=H_init, init="custom", n_components="auto"
+    )
+    assert H.shape == H_init.shape
+    assert W.shape == W_init.shape
+
+
+# TODO(1.6): remove
+def test_nmf_n_components_default_value_warning():
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((6, 5))
+    H = rng.random_sample((2, 5))
+    with pytest.warns(
+        FutureWarning, match="The default value of `n_components` will change from"
+    ):
+        non_negative_factorization(X, H=H)
+
+
+def test_nmf_n_components_auto_no_h_update():
+    # Tests that non_negative_factorization does not fail when setting
+    # n_components="auto" also tests that the inferred n_component
+    # value is the right one.
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((6, 5))
+    H_true = rng.random_sample((2, 5))
+    W, H, _ = non_negative_factorization(
+        X, H=H_true, n_components="auto", update_H=False
+    )  # should not fail
+    assert_allclose(H, H_true)
+    assert W.shape == (X.shape[0], H_true.shape[0])
+
+
+def test_nmf_w_h_not_used_warning():
+    # Check that warnings are raised if user provided W and H are not used
+    # and initialization overrides value of W or H
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((6, 5))
+    W_init = rng.random_sample((6, 2))
+    H_init = rng.random_sample((2, 5))
+    with pytest.warns(
+        RuntimeWarning,
+        match="When init!='custom', provided W or H are ignored",
+    ):
+        non_negative_factorization(X, H=H_init, update_H=True, n_components="auto")
+
+    with pytest.warns(
+        RuntimeWarning,
+        match="When init!='custom', provided W or H are ignored",
+    ):
+        non_negative_factorization(
+            X, W=W_init, H=H_init, update_H=True, n_components="auto"
+        )
+
+    with pytest.warns(
+        RuntimeWarning, match="When update_H=False, the provided initial W is not used."
+    ):
+        # When update_H is False, W is ignored regardless of init
+        # TODO: use the provided W when init="custom".
+        non_negative_factorization(
+            X, W=W_init, H=H_init, update_H=False, n_components="auto"
+        )
+
+
+def test_nmf_custom_init_shape_error():
+    # Check that an informative error is raised when custom initialization does not
+    # have the right shape
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((6, 5))
+    H = rng.random_sample((2, 5))
+    nmf = NMF(n_components=2, init="custom", random_state=0)
+
+    with pytest.raises(ValueError, match="Array with wrong first dimension passed"):
+        nmf.fit(X, H=H, W=rng.random_sample((5, 2)))
+
+    with pytest.raises(ValueError, match="Array with wrong second dimension passed"):
+        nmf.fit(X, H=H, W=rng.random_sample((6, 3)))
diff --git a/sklearn/tests/test_docstring_parameters.py b/sklearn/tests/test_docstring_parameters.py
--- a/sklearn/tests/test_docstring_parameters.py
+++ b/sklearn/tests/test_docstring_parameters.py
@@ -260,6 +260,10 @@ def test_fit_docstring_attributes(name, Estimator):
     ):
         est.set_params(force_alpha=True)
 
+    # TODO(1.6): remove (avoid FutureWarning)
+    if Estimator.__name__ in ("NMF", "MiniBatchNMF"):
+        est.set_params(n_components="auto")
+
     if Estimator.__name__ == "QuantileRegressor":
         solver = "highs" if sp_version >= parse_version("1.6.0") else "interior-point"
         est.set_params(solver=solver)