# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-14806）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
IterativeImputer behaviour on missing nan's in fit data
Why is this behaviour forced: 

_Features with missing values during transform which did not have any missing values during fit will be imputed with the initial imputation method only._

[https://scikit-learn.org/dev/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer](https://scikit-learn.org/dev/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer)

This means by default it will return the mean of that feature. I would prefer just fit one iteration of the chosen estimator and use that fitted estimator to impute missing values. 

Actual behaviour:
Example - The second feature missing np.nan --> mean imputation
``` python 
import numpy as np
from sklearn.impute import IterativeImputer
imp = IterativeImputer(max_iter=10, verbose=0)
imp.fit([[1, 2], [3, 6], [4, 8], [10, 20], [np.nan, 22], [7, 14]])

X_test = [[np.nan, 4], [6, np.nan], [np.nan, 6], [4, np.nan], [33, np.nan]]
print(np.round(imp.transform(X_test)))
```
```
Return:
[[ 2.  4.]
 [ 6. 12.]
 [ 3.  6.]
 [ 4. 12.]
 [33. 12.]]
```

Example adjusted - Second feature has np.nan values --> iterative imputation with estimator
``` python 
import numpy as np
from sklearn.impute import IterativeImputer
imp = IterativeImputer(max_iter=10, verbose=0)
imp.fit([[1, 2], [3, 6], [4, 8], [10, 20], [np.nan, 22], [7, np.nan]])

X_test = [[np.nan, 4], [6, np.nan], [np.nan, 6], [4, np.nan], [33, np.nan]]
print(np.round(imp.transform(X_test)))
```
```
Return:
[[ 2.  4.]
 [ 6. 12.]
 [ 3.  6.]
 [ 4. 8.]
 [33. 66.]]
```

Maybe [sklearn/impute.py](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/impute.py) line 679 to 683 should be optional with a parameter like force-iterimpute.


## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/impute/tests/test_impute.py b/sklearn/impute/tests/test_impute.py
--- a/sklearn/impute/tests/test_impute.py
+++ b/sklearn/impute/tests/test_impute.py
@@ -457,6 +457,18 @@ def test_imputation_missing_value_in_test_array(Imputer):
     imputer.fit(train).transform(test)
 
 
+@pytest.mark.parametrize("X", [[[1], [2]], [[1], [np.nan]]])
+def test_iterative_imputer_one_feature(X):
+    # check we exit early when there is a single feature
+    imputer = IterativeImputer().fit(X)
+    assert imputer.n_iter_ == 0
+    imputer = IterativeImputer()
+    imputer.fit([[1], [2]])
+    assert imputer.n_iter_ == 0
+    imputer.fit([[1], [np.nan]])
+    assert imputer.n_iter_ == 0
+
+
 def test_imputation_pipeline_grid_search():
     # Test imputation within a pipeline + gridsearch.
     X = sparse_random_matrix(100, 100, density=0.10)
@@ -587,6 +599,7 @@ def test_iterative_imputer_imputation_order(imputation_order):
                                max_iter=max_iter,
                                n_nearest_features=5,
                                sample_posterior=False,
+                               skip_complete=True,
                                min_value=0,
                                max_value=1,
                                verbose=1,
@@ -951,6 +964,36 @@ def test_iterative_imputer_catch_warning():
     assert not np.any(np.isnan(X_fill))
 
 
+@pytest.mark.parametrize(
+    "skip_complete", [True, False]
+)
+def test_iterative_imputer_skip_non_missing(skip_complete):
+    # check the imputing strategy when missing data are present in the
+    # testing set only.
+    # taken from: https://github.com/scikit-learn/scikit-learn/issues/14383
+    rng = np.random.RandomState(0)
+    X_train = np.array([
+        [5, 2, 2, 1],
+        [10, 1, 2, 7],
+        [3, 1, 1, 1],
+        [8, 4, 2, 2]
+    ])
+    X_test = np.array([
+        [np.nan, 2, 4, 5],
+        [np.nan, 4, 1, 2],
+        [np.nan, 1, 10, 1]
+    ])
+    imputer = IterativeImputer(
+        initial_strategy='mean', skip_complete=skip_complete, random_state=rng
+    )
+    X_test_est = imputer.fit(X_train).transform(X_test)
+    if skip_complete:
+        # impute with the initial strategy: 'mean'
+        assert_allclose(X_test_est[:, 0], np.mean(X_train[:, 0]))
+    else:
+        assert_allclose(X_test_est[:, 0], [11, 7, 12], rtol=1e-4)
+
+
 @pytest.mark.parametrize(
     "X_fit, X_trans, params, msg_err",
     [(np.array([[-1, 1], [1, 2]]), np.array([[-1, 1], [1, -1]]),