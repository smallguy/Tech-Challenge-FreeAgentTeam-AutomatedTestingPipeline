# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-12908）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
OneHotEncoder - add option for 1 of k-1 encoding
Like the title says. Would it be possible to add an option, say "independent = True" to OneHotEncoder that would return a 1 of k-1 encoding instead of a 1 of k encoding. This would be very useful to me when I am encoding categorical variables since the 1 of k encoding adds an extra (non-independent) degree of freedom to the model. It would also be nice if I could specify which category to keep as the baseline.

Something like:

```
X = np.array([12,24,36]).reshape(-1,1)  
OneHotEncoder(sparse=False, independent=True, baseline=24).fit_transform(X)  
Output: array([[ 1., 0.],
       [ 0., 0.],
       [ 0., 1.]])
```

OneHotEncoding - Defining a reference category 
In order to avoid multicollinearity in modelling, the number of dummy-coded variables needed should be one less than the number of categories. Therefore, it would be very code if OneHotEncoding could accept a reference category as an input variable. 

[MRG] ENH: add support for dropping first level of categorical feature
#### Reference Issues

Fixes #6053
Fixes #9073

#### What does this implement/fix? Explain your changes.
This Pull Request adds an extra argument to `DictVectorizer` that, if set to `True`, drops the first level of each categorical variable. This is extremely useful in a regression model that to not use regularisation, as it avoids multicollinearity.

#### Any other comments
Even though multicollinearity doesn't affect the predictions, it hugely affects the regression coefficients, which makes troublesome both model inspection and further usage of such coefficients.
[MRG] add drop_first option to OneHotEncoder
<!--
Thanks for contributing a pull request! Please ensure you have taken a look at
the contribution guidelines: https://github.com/scikit-learn/scikit-learn/blob/master/CONTRIBUTING.md#pull-request-checklist
-->

#### Reference Issues/PRs
<!--
Example: Fixes #1234. See also #3456.
Please use keywords (e.g., Fixes) to create link to the issues or pull requests
you resolved, so that they will automatically be closed when your pull request
is merged. See https://github.com/blog/1506-closing-issues-via-pull-requests
-->

Closes #6488

#### What does this implement/fix? Explain your changes.

This PR adds a `drop_first` option to `OneHotEncoder`.
Each feature is encoded into `n_unique_values - 1` columns instead of `n_unique_values` columns. The first one is dropped, resulting in all of the others being zero.

#### Any other comments?

This is incompatible with `handle_missing='ignore'` because the ignored missing categories result in all of the one-hot columns being zeros, which is also how the first category is treated when `drop_first=True`. So by allowing both, there would be no way to distinguish between a missing category and the first one.

<!--
Please be aware that we are a loose team of volunteers so patience is
necessary; assistance handling other issues is very welcome. We value
all user contributions, no matter how minor they are. If we are slow to
review, either the pull request needs some benchmarking, tinkering,
convincing, etc. or more likely the reviewers are simply busy. In either
case, we ask for your understanding during the review process.
For more information, see our FAQ on this topic:
http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention.

Thanks for contributing!
-->



## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/preprocessing/tests/test_encoders.py b/sklearn/preprocessing/tests/test_encoders.py
--- a/sklearn/preprocessing/tests/test_encoders.py
+++ b/sklearn/preprocessing/tests/test_encoders.py
@@ -96,6 +96,20 @@ def test_one_hot_encoder_sparse():
         enc.fit([[0], [1]])
     assert_raises(ValueError, enc.transform, [[0], [-1]])
 
+    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):
+        enc = OneHotEncoder(drop='first', n_values=1)
+        for method in (enc.fit, enc.fit_transform):
+            assert_raises_regex(
+                ValueError,
+                'The `categorical_features` and `n_values` keywords ',
+                method, [[0], [-1]])
+
+            enc = OneHotEncoder(drop='first', categorical_features='all')
+            assert_raises_regex(
+                ValueError,
+                'The `categorical_features` and `n_values` keywords ',
+                method, [[0], [-1]])
+
 
 def test_one_hot_encoder_dense():
     # check for sparse=False
@@ -278,7 +292,7 @@ def test_one_hot_encoder_no_categorical_features():
     enc = OneHotEncoder(categorical_features=cat)
     with ignore_warnings(category=(DeprecationWarning, FutureWarning)):
         X_tr = enc.fit_transform(X)
-    expected_features = np.array(list(), dtype='object')
+    expected_features = np.array([], dtype='object')
     assert_array_equal(X, X_tr)
     assert_array_equal(enc.get_feature_names(), expected_features)
     assert enc.categories_ == []
@@ -373,21 +387,25 @@ def test_one_hot_encoder(X):
     assert_allclose(Xtr.toarray(), [[0, 1, 1, 0,  1], [1, 0, 0, 1, 1]])
 
 
-def test_one_hot_encoder_inverse():
-    for sparse_ in [True, False]:
-        X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]
-        enc = OneHotEncoder(sparse=sparse_)
-        X_tr = enc.fit_transform(X)
-        exp = np.array(X, dtype=object)
-        assert_array_equal(enc.inverse_transform(X_tr), exp)
+@pytest.mark.parametrize('sparse_', [False, True])
+@pytest.mark.parametrize('drop', [None, 'first'])
+def test_one_hot_encoder_inverse(sparse_, drop):
+    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]
+    enc = OneHotEncoder(sparse=sparse_, drop=drop)
+    X_tr = enc.fit_transform(X)
+    exp = np.array(X, dtype=object)
+    assert_array_equal(enc.inverse_transform(X_tr), exp)
 
-        X = [[2, 55], [1, 55], [3, 55]]
-        enc = OneHotEncoder(sparse=sparse_, categories='auto')
-        X_tr = enc.fit_transform(X)
-        exp = np.array(X)
-        assert_array_equal(enc.inverse_transform(X_tr), exp)
+    X = [[2, 55], [1, 55], [3, 55]]
+    enc = OneHotEncoder(sparse=sparse_, categories='auto',
+                        drop=drop)
+    X_tr = enc.fit_transform(X)
+    exp = np.array(X)
+    assert_array_equal(enc.inverse_transform(X_tr), exp)
 
+    if drop is None:
         # with unknown categories
+        # drop is incompatible with handle_unknown=ignore
         X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]
         enc = OneHotEncoder(sparse=sparse_, handle_unknown='ignore',
                             categories=[['abc', 'def'], [1, 2],
@@ -407,10 +425,10 @@ def test_one_hot_encoder_inverse():
         exp[:, 1] = None
         assert_array_equal(enc.inverse_transform(X_tr), exp)
 
-        # incorrect shape raises
-        X_tr = np.array([[0, 1, 1], [1, 0, 1]])
-        msg = re.escape('Shape of the passed X data is not correct')
-        assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)
+    # incorrect shape raises
+    X_tr = np.array([[0, 1, 1], [1, 0, 1]])
+    msg = re.escape('Shape of the passed X data is not correct')
+    assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)
 
 
 @pytest.mark.parametrize("X, cat_exp, cat_dtype", [
@@ -687,3 +705,90 @@ def test_one_hot_encoder_warning():
     enc = OneHotEncoder()
     X = [['Male', 1], ['Female', 3]]
     np.testing.assert_no_warnings(enc.fit_transform, X)
+
+
+def test_one_hot_encoder_drop_manual():
+    cats_to_drop = ['def', 12, 3, 56]
+    enc = OneHotEncoder(drop=cats_to_drop)
+    X = [['abc', 12, 2, 55],
+         ['def', 12, 1, 55],
+         ['def', 12, 3, 56]]
+    trans = enc.fit_transform(X).toarray()
+    exp = [[1, 0, 1, 1],
+           [0, 1, 0, 1],
+           [0, 0, 0, 0]]
+    assert_array_equal(trans, exp)
+    dropped_cats = [cat[feature]
+                    for cat, feature in zip(enc.categories_,
+                                            enc.drop_idx_)]
+    assert_array_equal(dropped_cats, cats_to_drop)
+    assert_array_equal(np.array(X, dtype=object),
+                       enc.inverse_transform(trans))
+
+
+def test_one_hot_encoder_invalid_params():
+    enc = OneHotEncoder(drop='second')
+    assert_raises_regex(
+        ValueError,
+        "Wrong input for parameter `drop`.",
+        enc.fit, [["Male"], ["Female"]])
+
+    enc = OneHotEncoder(handle_unknown='ignore', drop='first')
+    assert_raises_regex(
+        ValueError,
+        "`handle_unknown` must be 'error'",
+        enc.fit, [["Male"], ["Female"]])
+
+    enc = OneHotEncoder(drop='first')
+    assert_raises_regex(
+        ValueError,
+        "The handling of integer data will change in version",
+        enc.fit, [[1], [2]])
+
+    enc = OneHotEncoder(drop='first', categories='auto')
+    assert_no_warnings(enc.fit_transform, [[1], [2]])
+
+    enc = OneHotEncoder(drop=np.asarray('b', dtype=object))
+    assert_raises_regex(
+        ValueError,
+        "Wrong input for parameter `drop`.",
+        enc.fit, [['abc', 2, 55], ['def', 1, 55], ['def', 3, 59]])
+
+    enc = OneHotEncoder(drop=['ghi', 3, 59])
+    assert_raises_regex(
+        ValueError,
+        "The following categories were supposed",
+        enc.fit, [['abc', 2, 55], ['def', 1, 55], ['def', 3, 59]])
+
+
+@pytest.mark.parametrize('drop', [['abc', 3], ['abc', 3, 41, 'a']])
+def test_invalid_drop_length(drop):
+    enc = OneHotEncoder(drop=drop)
+    assert_raises_regex(
+        ValueError,
+        "`drop` should have length equal to the number",
+        enc.fit, [['abc', 2, 55], ['def', 1, 55], ['def', 3, 59]])
+
+
+@pytest.mark.parametrize("density", [True, False],
+                         ids=['sparse', 'dense'])
+@pytest.mark.parametrize("drop", ['first',
+                                  ['a', 2, 'b']],
+                         ids=['first', 'manual'])
+def test_categories(density, drop):
+    ohe_base = OneHotEncoder(sparse=density)
+    ohe_test = OneHotEncoder(sparse=density, drop=drop)
+    X = [['c', 1, 'a'],
+         ['a', 2, 'b']]
+    ohe_base.fit(X)
+    ohe_test.fit(X)
+    assert_array_equal(ohe_base.categories_, ohe_test.categories_)
+    if drop == 'first':
+        assert_array_equal(ohe_test.drop_idx_, 0)
+    else:
+        for drop_cat, drop_idx, cat_list in zip(drop,
+                                                ohe_test.drop_idx_,
+                                                ohe_test.categories_):
+            assert cat_list[drop_idx] == drop_cat
+    assert isinstance(ohe_test.drop_idx_, np.ndarray)
+    assert ohe_test.drop_idx_.dtype == np.int_