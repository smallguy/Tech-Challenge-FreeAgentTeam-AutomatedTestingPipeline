# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-13333）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
DOC Improve doc of n_quantiles in QuantileTransformer 
#### Description
The `QuantileTransformer` uses numpy.percentile(X_train, .) as the estimator of the quantile function of the training data. To know this function perfectly we just need to take `n_quantiles=n_samples`. Then it is just a linear interpolation (which is done in the code afterwards). Therefore I don't think we should be able to choose `n_quantiles > n_samples` and we should prevent users from thinking that the higher `n_quantiles` the better the transformation. As mentioned by @GaelVaroquaux IRL it is however true that it can be relevant to choose `n_quantiles < n_samples` when `n_samples` is very large.

I suggest to add more information on the impact of `n_quantiles` in the doc which currently reads:
```python
Number of quantiles to be computed. It corresponds to the number of
landmarks used to discretize the cumulative distribution function.
```

For example using 100 times more landmarks result in the same transformation
```python
import numpy as np
from sklearn.preprocessing import QuantileTransformer
from sklearn.utils.testing import assert_allclose

n_samples = 100
X_train = np.random.randn(n_samples, 2)
X_test = np.random.randn(1000, 2)

qf_1 = QuantileTransformer(n_quantiles=n_samples)
qf_1.fit(X_train)
X_trans_1 = qf_1.transform(X_test)

qf_2 = QuantileTransformer(n_quantiles=10000)
qf_2.fit(X_train)
X_trans_2 = qf_2.transform(X_test)

assert_allclose(X_trans_1, X_trans_2)
```

Interestingly if you do not choose `n_quantiles > n_samples` correctly, the linear interpolation done afterwards does not correspond to the numpy.percentile(X_train, .) estimator. This is not "wrong" as these are only estimators of the true quantile function/cdf but I think it is confusing and would be better to stick with the original estimator. For instance, the following raises an AssertionError.
```python
import numpy as np
from sklearn.preprocessing import QuantileTransformer
from sklearn.utils.testing import assert_allclose

n_samples = 100
X_train = np.random.randn(n_samples, 2)
X_test = np.random.randn(1000, 2)

qf_1 = QuantileTransformer(n_quantiles=n_samples)
qf_1.fit(X_train)
X_trans_1 = qf_1.transform(X_test)

qf_2 = QuantileTransformer(n_quantiles=200)
qf_2.fit(X_train)
X_trans_2 = qf_2.transform(X_test)

assert_allclose(X_trans_1, X_trans_2)
```


## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/preprocessing/tests/test_data.py b/sklearn/preprocessing/tests/test_data.py
--- a/sklearn/preprocessing/tests/test_data.py
+++ b/sklearn/preprocessing/tests/test_data.py
@@ -1260,6 +1260,13 @@ def test_quantile_transform_check_error():
     assert_raise_message(ValueError,
                          'Expected 2D array, got scalar array instead',
                          transformer.transform, 10)
+    # check that a warning is raised is n_quantiles > n_samples
+    transformer = QuantileTransformer(n_quantiles=100)
+    warn_msg = "n_quantiles is set to n_samples"
+    with pytest.warns(UserWarning, match=warn_msg) as record:
+        transformer.fit(X)
+    assert len(record) == 1
+    assert transformer.n_quantiles_ == X.shape[0]
 
 
 def test_quantile_transform_sparse_ignore_zeros():