# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-15086）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
MultiTaskLassoCV with fit_intercept=True returns wrong results
There is something wrong with `MultiTaskLassoCV` and binary features. It always returns the same mse for all the alphas and hence chooses a huge regularization zeroing out all coefficients. The same holds for `MultiTaskElasticNet` too. However, this doesn't happen with `LassoCV`. Moreover it doesn't happen if I set `fit_intercept=False`, or if I generate random normal features.

I am working on anaconda, windows system, with python 3.7.1 and with scikit-learn v0.21.3, numpy v1.16.2.

Consider the following code:
```python
import numpy as np
from sklearn.linear_model import MultiTaskLassoCV, LassoCV
np.random.seed(123)
n = 1000
d = 3
X = np.random.binomial(1, .5, size=(n, d))
y = X[:, [0, 0]].copy()
est = MultiTaskLassoCV(n_alphas=5, fit_intercept=True).fit(X, y)
print(est.alpha_)
print(est.mse_path_)
print(est.coef_)
print(est.intercept_)
```
It returns
```
0.35353076317627596
[[0.25018905 0.2499848  0.24997129]
 [0.25018905 0.2499848  0.24997129]
 [0.25018905 0.2499848  0.24997129]
 [0.25018905 0.2499848  0.24997129]
 [0.25018905 0.2499848  0.24997129]]
[[ 0. -0.  0.]
 [ 0. -0.  0.]]
[0.496 0.496]
```

On the other hand, if I generate normal features X, then things are good:
```python
import numpy as np
from sklearn.linear_model import MultiTaskLassoCV, LassoCV
np.random.seed(123)
n = 1000
d = 3
X = np.random.normal(0, 1, size=(n, d))
y = X[:, [0, 0]].copy()
est = MultiTaskLassoCV(n_alphas=5, fit_intercept=True).fit(X, y)
print(est.alpha_)
print(est.mse_path_)
print(est.coef_)
print(est.intercept_)
```
which returns:
```
0.0012801092295924427
[[7.79350312e-01 9.01338896e-01 9.76488985e-01]
 [2.46452208e-02 2.85028386e-02 3.34510373e-02]
 [7.79350312e-04 9.01338896e-04 1.05781468e-03]
 [2.46452208e-05 2.85028386e-05 3.34510373e-05]
 [7.79350312e-07 9.01338896e-07 1.05781468e-06]]
[[ 0.999  0.    -0.   ]
 [ 0.999  0.    -0.   ]]
[2.72463186e-06 2.72463186e-06]
```

Also weirdly if I set `fit_intercept=False`, then things are good even with binary features:
```python
import numpy as np
from sklearn.linear_model import MultiTaskLassoCV, LassoCV
np.random.seed(123)
n = 1000
d = 3
X = np.random.binomial(1, .5, size=(n, d))
y = X[:, [0, 0]].copy()
est = MultiTaskLassoCV(n_alphas=5, fit_intercept=False).fit(X, y)
print(est.alpha_)
print(est.mse_path_)
print(est.coef_)
print(est.intercept_)
```
which returns
```
0.0007014499269370555
[[5.05988024e-01 4.83136584e-01 4.89033340e-01]
 [1.63288855e-02 1.52781203e-02 1.54645920e-02]
 [5.16364698e-04 4.83136584e-04 4.89033340e-04]
 [1.63288855e-05 1.52781203e-05 1.54645920e-05]
 [5.16364698e-07 4.83136584e-07 4.89033340e-07]]
[[0.999 0.    0.   ]
 [0.999 0.    0.   ]]
0.0
```



## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/linear_model/tests/test_coordinate_descent.py b/sklearn/linear_model/tests/test_coordinate_descent.py
--- a/sklearn/linear_model/tests/test_coordinate_descent.py
+++ b/sklearn/linear_model/tests/test_coordinate_descent.py
@@ -888,3 +888,13 @@ def fit(self, X, y):
     clf = LassoCV(precompute=precompute)
     clf.fit(X, y)
     assert calls > 0
+
+
+def test_multi_task_lasso_cv_dtype():
+    n_samples, n_features = 10, 3
+    rng = np.random.RandomState(42)
+    X = rng.binomial(1, .5, size=(n_samples, n_features))
+    X = X.astype(int)  # make it explicit that X is int
+    y = X[:, [0, 0]].copy()
+    est = MultiTaskLassoCV(n_alphas=5, fit_intercept=True).fit(X, y)
+    assert_array_almost_equal(est.coef_, [[1, 0, 0]] * 2, decimal=3)