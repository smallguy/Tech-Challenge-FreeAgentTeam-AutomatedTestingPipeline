# 修复代码生成提示词（实例ID：scikit-learn__scikit-learn-13472）
## 代码仓库
scikit-learn/scikit-learn

## 原始问题描述
GradientBoostingRegressor initial estimator does not play together with Pipeline
Using a pipeline as the initial estimator of GradientBoostingRegressor doesn't work due to incompatible signatures.

```python
import sklearn
import sklearn.pipeline
import sklearn.ensemble
import sklearn.decomposition
import sklearn.linear_model
import numpy as np
init = sklearn.pipeline.make_pipeline(sklearn.decomposition.PCA(), sklearn.linear_model.ElasticNet())
model = sklearn.ensemble.GradientBoostingRegressor(init=init)
x = np.random.rand(12, 3)
y = np.random.rand(12)
model.fit(x, y)

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/Users/Thomas/.local/miniconda3/envs/4cast/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py", line 1421, in fit
    self.init_.fit(X, y, sample_weight)
TypeError: fit() takes from 2 to 3 positional arguments but 4 were given
```
The signature of `Pipeline.fit` is

```python
# sklearn/pipeline.py
...
239 def fit(self, X, y=None, **fit_params):
...
```
which cannot be called with three positional arguments as above.

So I guess line 1421 in `sklearn/ensemble/gradient_boosting.py` should read
`self.init_.fit(X, y, sample_weight=sample_weight)` instead and the issue is solved. Right?

#### Versions
```python
>>> sklearn.show_versions()

System:
    python: 3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:14:59)  [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]
executable: /Users/Thomas/.local/miniconda3/envs/test/bin/python
   machine: Darwin-18.2.0-x86_64-i386-64bit

BLAS:
    macros: SCIPY_MKL_H=None, HAVE_CBLAS=None
  lib_dirs: /Users/Thomas/.local/miniconda3/envs/test/lib
cblas_libs: mkl_rt, pthread

Python deps:
       pip: 10.0.1
setuptools: 39.2.0
   sklearn: 0.20.2
     numpy: 1.16.1
     scipy: 1.2.0
    Cython: None
    pandas: 0.24.2
```


## 参考黄金补丁（正确的修复方案）
diff --git a/sklearn/ensemble/tests/test_gradient_boosting.py b/sklearn/ensemble/tests/test_gradient_boosting.py
--- a/sklearn/ensemble/tests/test_gradient_boosting.py
+++ b/sklearn/ensemble/tests/test_gradient_boosting.py
@@ -39,6 +39,9 @@
 from sklearn.exceptions import DataConversionWarning
 from sklearn.exceptions import NotFittedError
 from sklearn.dummy import DummyClassifier, DummyRegressor
+from sklearn.pipeline import make_pipeline
+from sklearn.linear_model import LinearRegression
+from sklearn.svm import NuSVR
 
 
 GRADIENT_BOOSTING_ESTIMATORS = [GradientBoostingClassifier,
@@ -1366,6 +1369,33 @@ def test_gradient_boosting_with_init(gb, dataset_maker, init_estimator):
         gb(init=init_est).fit(X, y, sample_weight=sample_weight)
 
 
+def test_gradient_boosting_with_init_pipeline():
+    # Check that the init estimator can be a pipeline (see issue #13466)
+
+    X, y = make_regression(random_state=0)
+    init = make_pipeline(LinearRegression())
+    gb = GradientBoostingRegressor(init=init)
+    gb.fit(X, y)  # pipeline without sample_weight works fine
+
+    with pytest.raises(
+            ValueError,
+            match='The initial estimator Pipeline does not support sample '
+                  'weights'):
+        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))
+
+    # Passing sample_weight to a pipeline raises a ValueError. This test makes
+    # sure we make the distinction between ValueError raised by a pipeline that
+    # was passed sample_weight, and a ValueError raised by a regular estimator
+    # whose input checking failed.
+    with pytest.raises(
+            ValueError,
+            match='nu <= 0 or nu > 1'):
+        # Note that NuSVR properly supports sample_weight
+        init = NuSVR(gamma='auto', nu=1.5)
+        gb = GradientBoostingRegressor(init=init)
+        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))
+
+
 @pytest.mark.parametrize('estimator, missing_method', [
     (GradientBoostingClassifier(init=LinearSVC()), 'predict_proba'),
     (GradientBoostingRegressor(init=OneHotEncoder()), 'predict')