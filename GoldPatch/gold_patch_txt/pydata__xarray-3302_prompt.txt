# 修复代码生成提示词（实例ID：pydata__xarray-3302）
## 代码仓库
pydata/xarray

## 原始问题描述
Improving interpolate_na()'s limit argument
I've been working with some time-series data with occasional nans peppered throughout. I want to interpolate small gaps of nans (say, when there is a single isolated nan or perhaps a block of two) but leave larger blocks as nans. That is, it's not appropriate to fill large gaps, but it acceptable to do so for small gaps.

I was hoping `interpolate_na()` with the `limit` argument would do exactly this, but it turns out that if you specify, say, `limit=2`, it will fill the first two nans of nan-blocks of any length, no matter how long. There are [definitely](https://stackoverflow.com/questions/43077166/interpolate-only-if-single-nan/43079055#43079055) [solutions](https://stackoverflow.com/questions/43082316/mask-only-where-consecutive-nans-exceeds-x#) for dealing with this, but it seems like a common issue, and has cropped up over on [Pandas](https://github.com/pandas-dev/pandas/issues/12187) as well.

I'm not able to attempt tackling this right now, but I guess I wanted to put in a feature request for an additional argument to `interpolate_na()` that would do this.



## 参考黄金补丁（正确的修复方案）
diff --git a/xarray/tests/test_missing.py b/xarray/tests/test_missing.py
--- a/xarray/tests/test_missing.py
+++ b/xarray/tests/test_missing.py
@@ -5,7 +5,13 @@
 import pytest
 
 import xarray as xr
-from xarray.core.missing import NumpyInterpolator, ScipyInterpolator, SplineInterpolator
+from xarray.core.missing import (
+    NumpyInterpolator,
+    ScipyInterpolator,
+    SplineInterpolator,
+    get_clean_interp_index,
+    _get_nan_block_lengths,
+)
 from xarray.core.pycompat import dask_array_type
 from xarray.tests import (
     assert_array_equal,
@@ -153,7 +159,7 @@ def test_interpolate_pd_compat_polynomial():
 def test_interpolate_unsorted_index_raises():
     vals = np.array([1, 2, 3], dtype=np.float64)
     expected = xr.DataArray(vals, dims="x", coords={"x": [2, 1, 3]})
-    with raises_regex(ValueError, "Index must be monotonicly increasing"):
+    with raises_regex(ValueError, "Index 'x' must be monotonically increasing"):
         expected.interpolate_na(dim="x", method="index")
 
 
@@ -169,12 +175,19 @@ def test_interpolate_invalid_interpolator_raises():
         da.interpolate_na(dim="x", method="foo")
 
 
+def test_interpolate_duplicate_values_raises():
+    data = np.random.randn(2, 3)
+    da = xr.DataArray(data, coords=[("x", ["a", "a"]), ("y", [0, 1, 2])])
+    with raises_regex(ValueError, "Index 'x' has duplicate values"):
+        da.interpolate_na(dim="x", method="foo")
+
+
 def test_interpolate_multiindex_raises():
     data = np.random.randn(2, 3)
     data[1, 1] = np.nan
     da = xr.DataArray(data, coords=[("x", ["a", "b"]), ("y", [0, 1, 2])])
     das = da.stack(z=("x", "y"))
-    with raises_regex(TypeError, "Index must be castable to float64"):
+    with raises_regex(TypeError, "Index 'z' must be castable to float64"):
         das.interpolate_na(dim="z")
 
 
@@ -439,3 +452,114 @@ def test_ffill_dataset(ds):
 @requires_bottleneck
 def test_bfill_dataset(ds):
     ds.ffill(dim="time")
+
+
+@requires_bottleneck
+@pytest.mark.parametrize(
+    "y, lengths",
+    [
+        [np.arange(9), [[3, 3, 3, 0, 3, 3, 0, 2, 2]]],
+        [np.arange(9) * 3, [[9, 9, 9, 0, 9, 9, 0, 6, 6]]],
+        [[0, 2, 5, 6, 7, 8, 10, 12, 14], [[6, 6, 6, 0, 4, 4, 0, 4, 4]]],
+    ],
+)
+def test_interpolate_na_nan_block_lengths(y, lengths):
+    arr = [[np.nan, np.nan, np.nan, 1, np.nan, np.nan, 4, np.nan, np.nan]]
+    da = xr.DataArray(arr * 2, dims=["x", "y"], coords={"x": [0, 1], "y": y})
+    index = get_clean_interp_index(da, dim="y", use_coordinate=True)
+    actual = _get_nan_block_lengths(da, dim="y", index=index)
+    expected = da.copy(data=lengths * 2)
+    assert_equal(actual, expected)
+
+
+@pytest.fixture
+def da_time():
+    return xr.DataArray(
+        [np.nan, 1, 2, np.nan, np.nan, 5, np.nan, np.nan, np.nan, np.nan, 10],
+        dims=["t"],
+    )
+
+
+def test_interpolate_na_max_gap_errors(da_time):
+    with raises_regex(
+        NotImplementedError, "max_gap not implemented for unlabeled coordinates"
+    ):
+        da_time.interpolate_na("t", max_gap=1)
+
+    with raises_regex(ValueError, "max_gap must be a scalar."):
+        da_time.interpolate_na("t", max_gap=(1,))
+
+    da_time["t"] = pd.date_range("2001-01-01", freq="H", periods=11)
+    with raises_regex(TypeError, "Underlying index is"):
+        da_time.interpolate_na("t", max_gap=1)
+
+    with raises_regex(TypeError, "Expected integer or floating point"):
+        da_time.interpolate_na("t", max_gap="1H", use_coordinate=False)
+
+    with raises_regex(ValueError, "Could not convert 'huh' to timedelta64"):
+        da_time.interpolate_na("t", max_gap="huh")
+
+
+@requires_bottleneck
+@pytest.mark.parametrize(
+    "time_range_func",
+    [pd.date_range, pytest.param(xr.cftime_range, marks=pytest.mark.xfail)],
+)
+@pytest.mark.parametrize("transform", [lambda x: x, lambda x: x.to_dataset(name="a")])
+@pytest.mark.parametrize(
+    "max_gap", ["3H", np.timedelta64(3, "h"), pd.to_timedelta("3H")]
+)
+def test_interpolate_na_max_gap_time_specifier(
+    da_time, max_gap, transform, time_range_func
+):
+    da_time["t"] = time_range_func("2001-01-01", freq="H", periods=11)
+    expected = transform(
+        da_time.copy(data=[np.nan, 1, 2, 3, 4, 5, np.nan, np.nan, np.nan, np.nan, 10])
+    )
+    actual = transform(da_time).interpolate_na("t", max_gap=max_gap)
+    assert_equal(actual, expected)
+
+
+@requires_bottleneck
+@pytest.mark.parametrize(
+    "coords",
+    [
+        pytest.param(None, marks=pytest.mark.xfail()),
+        {"x": np.arange(4), "y": np.arange(11)},
+    ],
+)
+def test_interpolate_na_2d(coords):
+    da = xr.DataArray(
+        [
+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+        ],
+        dims=["x", "y"],
+        coords=coords,
+    )
+
+    actual = da.interpolate_na("y", max_gap=2)
+    expected_y = da.copy(
+        data=[
+            [1, 2, 3, 4, 5, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, np.nan, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, 4, 5, 6, 7, np.nan, np.nan, np.nan, 11],
+        ]
+    )
+    assert_equal(actual, expected_y)
+
+    actual = da.interpolate_na("x", max_gap=3)
+    expected_x = xr.DataArray(
+        [
+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+            [1, 2, 3, 4, np.nan, 6, 7, np.nan, np.nan, np.nan, 11],
+        ],
+        dims=["x", "y"],
+        coords=coords,
+    )
+    assert_equal(actual, expected_x)