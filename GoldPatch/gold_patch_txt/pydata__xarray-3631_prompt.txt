# 修复代码生成提示词（实例ID：pydata__xarray-3631）
## 代码仓库
pydata/xarray

## 原始问题描述
interp with long cftime coordinates raises an error
#### MCVE Code Sample
<!-- In order for the maintainers to efficiently understand and prioritize issues, we ask you post a "Minimal, Complete and Verifiable Example" (MCVE): http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports -->

```
In [1]: import xarray as xr

In [2]: times = xr.cftime_range('0001', periods=3, freq='500Y')

In [3]: da = xr.DataArray(range(3), dims=['time'], coords=[times])

In [4]: da.interp(time=['0002-05-01'])
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-4-f781cb4d500e> in <module>
----> 1 da.interp(time=['0002-05-01'])

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/dataarray.py in interp(self, coords, method, assume_sorted, kwargs, **coords_kwargs)
   1353             kwargs=kwargs,
   1354             assume_sorted=assume_sorted,
-> 1355             **coords_kwargs,
   1356         )
   1357         return self._from_temp_dataset(ds)

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/dataset.py in interp(self, coords, method, assume_sorted, kwargs, **coords_kwargs)
   2565                     if k in var.dims
   2566                 }
-> 2567                 variables[name] = missing.interp(var, var_indexers, method, **kwargs)
   2568             elif all(d not in indexers for d in var.dims):
   2569                 # keep unrelated object array

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/missing.py in interp(var, indexes_coords, method, **kwargs)
    607     new_dims = broadcast_dims + list(destination[0].dims)
    608     interped = interp_func(
--> 609         var.transpose(*original_dims).data, x, destination, method, kwargs
    610     )
    611

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/missing.py in interp_func(var, x, new_x, method, kwargs)
    683         )
    684
--> 685     return _interpnd(var, x, new_x, func, kwargs)
    686
    687

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/missing.py in _interpnd(var, x, new_x, func, kwargs)
    698
    699 def _interpnd(var, x, new_x, func, kwargs):
--> 700     x, new_x = _floatize_x(x, new_x)
    701
    702     if len(x) == 1:

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/missing.py in _floatize_x(x, new_x)
    556             # represented by float.
    557             xmin = x[i].values.min()
--> 558             x[i] = x[i]._to_numeric(offset=xmin, dtype=np.float64)
    559             new_x[i] = new_x[i]._to_numeric(offset=xmin, dtype=np.float64)
    560     return x, new_x

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/variable.py in _to_numeric(self, offset, datetime_unit, dtype)
   2001         """
   2002         numeric_array = duck_array_ops.datetime_to_numeric(
-> 2003             self.data, offset, datetime_unit, dtype
   2004         )
   2005         return type(self)(self.dims, numeric_array, self._attrs)

~/Software/miniconda3/envs/xarray-tests/lib/python3.7/site-packages/xarray/core/duck_array_ops.py in datetime_to_numeric(array, offset, datetime_unit, dtype)
    410     if array.dtype.kind in "mM":
    411         return np.where(isnull(array), np.nan, array.astype(dtype))
--> 412     return array.astype(dtype)
    413
    414

TypeError: float() argument must be a string or a number, not 'datetime.timedelta'
```

#### Problem Description
<!-- this should explain why the current behavior is a problem and why the expected output is a better solution -->

In principle we should be able to get this to work.  The issue stems from the following logic in `datetime_to_numeric`:
https://github.com/pydata/xarray/blob/45fd0e63f43cf313b022a33aeec7f0f982e1908b/xarray/core/duck_array_ops.py#L402-L404
Here we are relying on pandas to convert an array of `datetime.timedelta` objects to an array with dtype `timedelta64[ns]`.  If the array of `datetime.timedelta` objects cannot be safely converted to `timedelta64[ns]` (e.g. due to an integer overflow) then this line is silently a no-op which leads to the error downstream at the dtype conversion step.  This is my fault originally for suggesting this approach, https://github.com/pydata/xarray/pull/2668#discussion_r247271576. 

~~To solve this I think we'll need to write our own logic to convert `datetime.timedelta` objects to numeric values instead of relying on pandas/NumPy.~~ (as @huard notes we should be able to use NumPy directly here for the conversion).  We should not consider ourselves beholden to using nanosecond resolution for a couple of reasons:
1. `datetime.timedelta` objects do not natively support nanosecond resolution; [they have microsecond resolution](https://docs.python.org/3/library/datetime.html#available-types) natively, which corresponds with a [NumPy timedelta range of +/- 2.9e5 years](https://docs.scipy.org/doc/numpy/reference/arrays.datetime.html#datetime-units).
2. One motivation/use-case for cftime dates is that they can represent long time periods that cannot be represented using a standard `DatetimeIndex`.  We should do everything we can to support this with a `CFTimeIndex`.

@huard @dcherian this is an important issue we'll need to solve to be able to use a fixed offset for cftime dates for an application like `polyfit`/`polyval`.  

xref: #3349 and #3631.

#### Output of ``xr.show_versions()``
<details>

INSTALLED VERSIONS
------------------
commit: None
python: 3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 14:38:56)
[Clang 4.0.1 (tags/RELEASE_401/final)]
python-bits: 64
OS: Darwin
OS-release: 19.0.0
machine: x86_64
processor: i386
byteorder: little
LC_ALL: None
LANG: en_US.UTF-8
LOCALE: en_US.UTF-8
libhdf5: 1.10.5
libnetcdf: None

xarray: 0.14.1
pandas: 0.25.0
numpy: 1.17.0
scipy: 1.3.1
netCDF4: None
pydap: installed
h5netcdf: 0.7.4
h5py: 2.9.0
Nio: None
zarr: 2.3.2
cftime: 1.0.4.2
nc_time_axis: None
PseudoNetCDF: None
rasterio: 1.0.25
cfgrib: 0.9.7.1
iris: None
bottleneck: 1.2.1
dask: 2.9.0+2.gd0daa5bc
distributed: 2.9.0
matplotlib: 3.1.1
cartopy: None
seaborn: 0.9.0
numbagg: installed
setuptools: 42.0.2.post20191201
pip: 19.2.2
conda: None
pytest: 5.0.1
IPython: 7.10.1
sphinx: None

</details>



## 参考黄金补丁（正确的修复方案）
diff --git a/xarray/tests/test_duck_array_ops.py b/xarray/tests/test_duck_array_ops.py
--- a/xarray/tests/test_duck_array_ops.py
+++ b/xarray/tests/test_duck_array_ops.py
@@ -1,6 +1,7 @@
 import warnings
 from textwrap import dedent
 
+import datetime as dt
 import numpy as np
 import pandas as pd
 import pytest
@@ -19,6 +20,10 @@
     rolling_window,
     stack,
     where,
+    py_timedelta_to_float,
+    np_timedelta64_to_float,
+    pd_timedelta_to_float,
+    timedelta_to_numeric,
 )
 from xarray.core.pycompat import dask_array_type
 from xarray.testing import assert_allclose, assert_equal
@@ -672,13 +677,15 @@ def test_datetime_to_numeric_datetime64():
 
 @requires_cftime
 def test_datetime_to_numeric_cftime():
-    times = cftime_range("2000", periods=5, freq="7D").values
-    result = duck_array_ops.datetime_to_numeric(times, datetime_unit="h")
+    times = cftime_range("2000", periods=5, freq="7D", calendar="standard").values
+    result = duck_array_ops.datetime_to_numeric(times, datetime_unit="h", dtype=int)
     expected = 24 * np.arange(0, 35, 7)
     np.testing.assert_array_equal(result, expected)
 
     offset = times[1]
-    result = duck_array_ops.datetime_to_numeric(times, offset=offset, datetime_unit="h")
+    result = duck_array_ops.datetime_to_numeric(
+        times, offset=offset, datetime_unit="h", dtype=int
+    )
     expected = 24 * np.arange(-7, 28, 7)
     np.testing.assert_array_equal(result, expected)
 
@@ -686,3 +693,70 @@ def test_datetime_to_numeric_cftime():
     result = duck_array_ops.datetime_to_numeric(times, datetime_unit="h", dtype=dtype)
     expected = 24 * np.arange(0, 35, 7).astype(dtype)
     np.testing.assert_array_equal(result, expected)
+
+
+@requires_cftime
+def test_datetime_to_numeric_potential_overflow():
+    import cftime
+
+    times = pd.date_range("2000", periods=5, freq="7D").values.astype("datetime64[us]")
+    cftimes = cftime_range(
+        "2000", periods=5, freq="7D", calendar="proleptic_gregorian"
+    ).values
+
+    offset = np.datetime64("0001-01-01")
+    cfoffset = cftime.DatetimeProlepticGregorian(1, 1, 1)
+
+    result = duck_array_ops.datetime_to_numeric(
+        times, offset=offset, datetime_unit="D", dtype=int
+    )
+    cfresult = duck_array_ops.datetime_to_numeric(
+        cftimes, offset=cfoffset, datetime_unit="D", dtype=int
+    )
+
+    expected = 730119 + np.arange(0, 35, 7)
+
+    np.testing.assert_array_equal(result, expected)
+    np.testing.assert_array_equal(cfresult, expected)
+
+
+def test_py_timedelta_to_float():
+    assert py_timedelta_to_float(dt.timedelta(days=1), "ns") == 86400 * 1e9
+    assert py_timedelta_to_float(dt.timedelta(days=1e6), "ps") == 86400 * 1e18
+    assert py_timedelta_to_float(dt.timedelta(days=1e6), "ns") == 86400 * 1e15
+    assert py_timedelta_to_float(dt.timedelta(days=1e6), "us") == 86400 * 1e12
+    assert py_timedelta_to_float(dt.timedelta(days=1e6), "ms") == 86400 * 1e9
+    assert py_timedelta_to_float(dt.timedelta(days=1e6), "s") == 86400 * 1e6
+    assert py_timedelta_to_float(dt.timedelta(days=1e6), "D") == 1e6
+
+
+@pytest.mark.parametrize(
+    "td, expected",
+    ([np.timedelta64(1, "D"), 86400 * 1e9], [np.timedelta64(1, "ns"), 1.0]),
+)
+def test_np_timedelta64_to_float(td, expected):
+    out = np_timedelta64_to_float(td, datetime_unit="ns")
+    np.testing.assert_allclose(out, expected)
+    assert isinstance(out, float)
+
+    out = np_timedelta64_to_float(np.atleast_1d(td), datetime_unit="ns")
+    np.testing.assert_allclose(out, expected)
+
+
+@pytest.mark.parametrize(
+    "td, expected", ([pd.Timedelta(1, "D"), 86400 * 1e9], [pd.Timedelta(1, "ns"), 1.0])
+)
+def test_pd_timedelta_to_float(td, expected):
+    out = pd_timedelta_to_float(td, datetime_unit="ns")
+    np.testing.assert_allclose(out, expected)
+    assert isinstance(out, float)
+
+
+@pytest.mark.parametrize(
+    "td", [dt.timedelta(days=1), np.timedelta64(1, "D"), pd.Timedelta(1, "D"), "1 day"],
+)
+def test_timedelta_to_numeric(td):
+    # Scalar input
+    out = timedelta_to_numeric(td, "ns")
+    np.testing.assert_allclose(out, 86400 * 1e9)
+    assert isinstance(out, float)
diff --git a/xarray/tests/test_interp.py b/xarray/tests/test_interp.py
--- a/xarray/tests/test_interp.py
+++ b/xarray/tests/test_interp.py
@@ -662,3 +662,10 @@ def test_datetime_interp_noerror():
         coords={"time": pd.date_range("01-01-2001", periods=50, freq="H")},
     )
     a.interp(x=xi, time=xi.time)  # should not raise an error
+
+
+@requires_cftime
+def test_3641():
+    times = xr.cftime_range("0001", periods=3, freq="500Y")
+    da = xr.DataArray(range(3), dims=["time"], coords=[times])
+    da.interp(time=["0002-05-01"])
diff --git a/xarray/tests/test_missing.py b/xarray/tests/test_missing.py
--- a/xarray/tests/test_missing.py
+++ b/xarray/tests/test_missing.py
@@ -16,18 +16,34 @@
 from xarray.tests import (
     assert_array_equal,
     assert_equal,
+    assert_allclose,
     raises_regex,
     requires_bottleneck,
     requires_dask,
     requires_scipy,
+    requires_cftime,
 )
 
+from xarray.tests.test_cftime_offsets import _CFTIME_CALENDARS
+
 
 @pytest.fixture
 def da():
     return xr.DataArray([0, np.nan, 1, 2, np.nan, 3, 4, 5, np.nan, 6, 7], dims="time")
 
 
+@pytest.fixture
+def cf_da():
+    def _cf_da(calendar, freq="1D"):
+        times = xr.cftime_range(
+            start="1970-01-01", freq=freq, periods=10, calendar=calendar
+        )
+        values = np.arange(10)
+        return xr.DataArray(values, dims=("time",), coords={"time": times})
+
+    return _cf_da
+
+
 @pytest.fixture
 def ds():
     ds = xr.Dataset()
@@ -472,6 +488,42 @@ def test_interpolate_na_nan_block_lengths(y, lengths):
     assert_equal(actual, expected)
 
 
+@requires_cftime
+@pytest.mark.parametrize("calendar", _CFTIME_CALENDARS)
+def test_get_clean_interp_index_cf_calendar(cf_da, calendar):
+    """The index for CFTimeIndex is in units of days. This means that if two series using a 360 and 365 days
+    calendar each have a trend of .01C/year, the linear regression coefficients will be different because they
+    have different number of days.
+
+    Another option would be to have an index in units of years, but this would likely create other difficulties.
+    """
+    i = get_clean_interp_index(cf_da(calendar), dim="time")
+    np.testing.assert_array_equal(i, np.arange(10) * 1e9 * 86400)
+
+
+@requires_cftime
+@pytest.mark.parametrize(
+    ("calendar", "freq"), zip(["gregorian", "proleptic_gregorian"], ["1D", "1M", "1Y"])
+)
+def test_get_clean_interp_index_dt(cf_da, calendar, freq):
+    """In the gregorian case, the index should be proportional to normal datetimes."""
+    g = cf_da(calendar, freq=freq)
+    g["stime"] = xr.Variable(data=g.time.to_index().to_datetimeindex(), dims=("time",))
+
+    gi = get_clean_interp_index(g, "time")
+    si = get_clean_interp_index(g, "time", use_coordinate="stime")
+    np.testing.assert_array_equal(gi, si)
+
+
+def test_get_clean_interp_index_potential_overflow():
+    da = xr.DataArray(
+        [0, 1, 2],
+        dims=("time",),
+        coords={"time": xr.cftime_range("0000-01-01", periods=3, calendar="360_day")},
+    )
+    get_clean_interp_index(da, "time")
+
+
 @pytest.fixture
 def da_time():
     return xr.DataArray(
@@ -490,7 +542,7 @@ def test_interpolate_na_max_gap_errors(da_time):
         da_time.interpolate_na("t", max_gap=(1,))
 
     da_time["t"] = pd.date_range("2001-01-01", freq="H", periods=11)
-    with raises_regex(TypeError, "Underlying index is"):
+    with raises_regex(TypeError, "Expected value of type str"):
         da_time.interpolate_na("t", max_gap=1)
 
     with raises_regex(TypeError, "Expected integer or floating point"):
@@ -501,10 +553,7 @@ def test_interpolate_na_max_gap_errors(da_time):
 
 
 @requires_bottleneck
-@pytest.mark.parametrize(
-    "time_range_func",
-    [pd.date_range, pytest.param(xr.cftime_range, marks=pytest.mark.xfail)],
-)
+@pytest.mark.parametrize("time_range_func", [pd.date_range, xr.cftime_range])
 @pytest.mark.parametrize("transform", [lambda x: x, lambda x: x.to_dataset(name="a")])
 @pytest.mark.parametrize(
     "max_gap", ["3H", np.timedelta64(3, "h"), pd.to_timedelta("3H")]
@@ -517,7 +566,7 @@ def test_interpolate_na_max_gap_time_specifier(
         da_time.copy(data=[np.nan, 1, 2, 3, 4, 5, np.nan, np.nan, np.nan, np.nan, 10])
     )
     actual = transform(da_time).interpolate_na("t", max_gap=max_gap)
-    assert_equal(actual, expected)
+    assert_allclose(actual, expected)
 
 
 @requires_bottleneck