import datetime
from mcp.server.fastmcp import FastMCP
mcp = FastMCP("Demo", log_level="ERROR")

from pathlib import Path
from rich.tree import Tree
from rich.console import Console
from io import StringIO
import os
from typing import Optional, Dict, List, Any, Tuple
import sys
import json
import logging
from sandbox import _task_sandboxes  # ä»sd_filemessageå¤ç”¨æ²™ç®±æ£€æŸ¥é€»è¾‘
from logger import get_logger

# # æ—¥å¿—é…ç½®
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)

def normalize_file_path(path: str) -> str:
    """æ ‡å‡†åŒ–æ–‡ä»¶è·¯å¾„ï¼ˆå…¼å®¹Windowså¤§å°å†™ä¸æ•æ„Ÿç‰¹æ€§ï¼‰
    
    ç»Ÿä¸€è·¯å¾„æ ¼å¼ï¼šè½¬æ¢ä¸ºPOSIXæ ¼å¼å¹¶è½¬ä¸ºå°å†™ï¼Œè§£å†³ä¸åŒç³»ç»Ÿè·¯å¾„æ ¼å¼å·®å¼‚é—®é¢˜
    
    Args:
        path: åŸå§‹æ–‡ä»¶è·¯å¾„
    
    Returns:
        æ ‡å‡†åŒ–åçš„è·¯å¾„å­—ç¬¦ä¸²
    """
    if not path:
        return ""
    return Path(path).as_posix().lower()


def recursively_find_file_in_json_tree(tree_data: dict, target_path: str) -> dict | None:
    """é€’å½’éå†JSONæ ‘çŠ¶ç»“æ„ï¼ŒæŸ¥æ‰¾æŒ‡å®šè·¯å¾„çš„æ–‡ä»¶ä¿¡æ¯
    
    éå†ç›®å½•ç»“æ„çš„JSONæ•°æ®ï¼ŒåŒ¹é…ç›®æ ‡æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼ˆå¿½ç•¥å¤§å°å†™å’Œè·¯å¾„åˆ†éš”ç¬¦å·®å¼‚ï¼‰
    
    Args:
        tree_data: è§£æåçš„æ ‘çŠ¶ç»“æ„JSONå­—å…¸
        target_path: è¦æŸ¥æ‰¾çš„æ–‡ä»¶å®Œæ•´è·¯å¾„
    
    Returns:
        åŒ¹é…çš„æ–‡ä»¶èŠ‚ç‚¹å­—å…¸ï¼ˆè‹¥æ‰¾åˆ°ä¸”ä¸ºæ–‡ä»¶ï¼‰ï¼›Noneï¼ˆæœªæ‰¾åˆ°æˆ–ç›®æ ‡ä¸ºç›®å½•ï¼‰
    """
    target_path_norm = normalize_file_path(target_path)
    current_path_norm = normalize_file_path(tree_data.get("full_path", ""))

    # æ£€æŸ¥å½“å‰èŠ‚ç‚¹æ˜¯å¦ä¸ºç›®æ ‡æ–‡ä»¶
    if tree_data.get("type") == "file" and current_path_norm == target_path_norm:
        return tree_data
    
    # è‹¥ä¸ºç›®å½•ï¼Œé€’å½’éå†å­èŠ‚ç‚¹
    if tree_data.get("type") == "directory" and tree_data.get("children"):
        for child in tree_data["children"]:
            found_node = recursively_find_file_in_json_tree(child, target_path)
            if found_node is not None:
                return found_node
    
    return None


def _format_file_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°ä¸ºäººç±»å¯è¯»æ ¼å¼"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    size = float(size_bytes)
    
    while size >= 1024.0 and i < len(size_names) - 1:
        size /= 1024.0
        i += 1
    
    return f"{int(size) if i == 0 else size:.1f} {size_names[i]}"

def _get_file_type_description(extension: str) -> str:
    """æ ¹æ®æ‰©å±•åè¿”å›æ–‡ä»¶ç±»å‹æè¿°"""
    type_map = {
        '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
        '.html': 'HTML', '.css': 'CSS', '.json': 'JSON', '.xml': 'XML',
        '.yaml': 'YAML', '.yml': 'YAML', '.toml': 'TOML', '.ini': 'Config',
        '.conf': 'Config', '.cfg': 'Config', '.txt': 'Text', '.md': 'Markdown',
        '.rst': 'reStruct', '.csv': 'CSV Data', '.tsv': 'TSV Data',
        '.xlsx': 'Excel', '.xls': 'Excel', '.pdf': 'PDF', '.png': 'PNG Image',
        '.jpg': 'JPEG Image', '.jpeg': 'JPEG Image', '.gif': 'GIF Image',
        '.svg': 'SVG Image', '.bmp': 'BMP Image', '.webp': 'WebP Image',
        '.mp4': 'Video', '.avi': 'Video', '.mov': 'Video', '.mp3': 'Audio',
        '.wav': 'Audio', '.zip': 'Archive', '.tar': 'Archive', '.gz': 'Archive',
        '.rar': 'Archive', '.sql': 'SQL', '.db': 'Database', '.sqlite': 'SQLite',
        '.log': 'Log', '.sh': 'Shell', '.bat': 'Batch', '.ps1': 'PowerShell',
        '.r': 'R Script', '.ipynb': 'Jupyter NB'
    }
    return type_map.get(extension, 'Unknown')

def get_workspace_dir(task_cache_dir: Optional[str] = None) -> str:
    """è·å–/åˆ›å»ºå·¥ä½œåŒºç›®å½•ï¼ˆå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰"""
    if not task_cache_dir:
        raise ValueError("å¿…é¡»æä¾›task_cache_diræ¥å®šä½å·¥ä½œåŒºã€‚")
    
    ospath = os.getenv("OSPATH")
    workspace_dir = Path(ospath) / task_cache_dir if ospath else Path(task_cache_dir)
    workspace_dir.mkdir(parents=True, exist_ok=True)
    return str(workspace_dir)

def _build_tree_and_stats_recursive(path: Path) -> Tuple[Dict[str, Any], int, int, Dict[str, Dict[str, int]]]:
    """
    å•æ¬¡é€’å½’å®Œæˆï¼šæ„å»ºæ ‘çŠ¶ç»“æ„ + ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯ï¼ˆæ ¸å¿ƒä¼˜åŒ–å‡½æ•°ï¼‰
    è¿”å›å€¼ï¼š
        node: æ ‘èŠ‚ç‚¹å­—å…¸
        total_files: å½“å‰è·¯å¾„ä¸‹çš„æ€»æ–‡ä»¶æ•°
        total_size: å½“å‰è·¯å¾„ä¸‹çš„æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        file_types: å½“å‰è·¯å¾„ä¸‹çš„æ–‡ä»¶ç±»å‹åˆ†å¸ƒ {åç¼€: {count: æ•°é‡, size: å¤§å°}}
    """

    node = {
        "name": path.name,
        "full_path": str(path),
        "type": "directory" if path.is_dir() else "file",
        "children": [] if path.is_dir() else None,
        "error": None
    }

    total_files = 0
    total_size = 0
    file_types = {}

    try:
        if path.is_file():
            # å¤„ç†æ–‡ä»¶ï¼šå¡«å……æ–‡ä»¶è¯¦æƒ… + åˆå§‹åŒ–ç»Ÿè®¡
            stat = path.stat()
            suffix = path.suffix.lower() or "no_extension"
            file_size = stat.st_size
            
            # å¡«å……æ–‡ä»¶èŠ‚ç‚¹è¯¦æƒ…
            node.update({
                "size_bytes": file_size,
                "size_human": _format_file_size(file_size),
                "modified_time": datetime.datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
                "extension": suffix,
                "file_type": _get_file_type_description(suffix)
            })
            
            # ç»Ÿè®¡å½“å‰æ–‡ä»¶
            total_files = 1
            total_size = file_size
            file_types[suffix] = {"count": 1, "size": file_size}

        else:
            # å¤„ç†ç›®å½•ï¼šé€’å½’éå†å­é¡¹ + æ±‡æ€»ç»Ÿè®¡
            for child in sorted(path.iterdir()):
                child_node, child_files, child_size, child_types = _build_tree_and_stats_recursive(child)
                node["children"].append(child_node)
                
                # æ±‡æ€»å­èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
                total_files += child_files
                total_size += child_size
                
                # åˆå¹¶æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
                for ext, info in child_types.items():
                    if ext not in file_types:
                        file_types[ext] = {"count": 0, "size": 0}
                    file_types[ext]["count"] += info["count"]
                    file_types[ext]["size"] += info["size"]

    except PermissionError:
        node["error"] = "Permission denied (æƒé™ä¸è¶³)"
    except OSError as e:
        node["error"] = f"OS error: {str(e)}"
    except Exception as e:
        node["error"] = f"Unexpected error: {str(e)}"
    
    return node, total_files, total_size, file_types

@mcp.tool()
def get_workspace_structure(task_cache_dir: str ) -> str:
    """
    è·å–å¸¦è¯¦ç»†ä¿¡æ¯çš„å·¥ä½œåŒºæ ‘çŠ¶ç»“æ„ + å…¨é‡æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        task_cache_dir: å·¥ä½œåŒºæ ¹ç›®å½•è·¯å¾„
    
    Returns:
        å¯¹åº”æ ¼å¼çš„å·¥ä½œåŒºç»“æ„(ä¿å­˜åœ¨file_struct.json)+ç»Ÿè®¡ä¿¡æ¯å­—ç¬¦ä¸²(ä¿å­˜åœ¨total_mes.txt)
    """
    workspace_dir = get_workspace_dir(task_cache_dir)
    workspace_path = Path(workspace_dir)
    
    if not workspace_path.exists():
        error_result = {
            "error": "Workspace directory does not exist",
            "path": workspace_dir
        }
        return json.dumps(error_result, ensure_ascii=False, indent=2) if return_format == "json" else f"ğŸ“‚ å·¥ä½œåŒºç›®å½•ä¸å­˜åœ¨: {workspace_dir}"
    
    tree_json, total_files, total_size, file_types = _build_tree_and_stats_recursive(workspace_path)
    
    # æ•´åˆsd_filemessageçš„å…¨é‡ç»Ÿè®¡ä¿¡æ¯ï¼ˆå«æ²™ç®±çŠ¶æ€ï¼‰
    sandbox_active = workspace_dir in _task_sandboxes
    full_stats = {
        "workspace_path": workspace_dir,
        "total_files": total_files,
        "total_size_bytes": total_size,
        "total_size_human": _format_file_size(total_size),
        "sandbox_active": sandbox_active,
        "environment_persistent": sandbox_active,
        "file_type_distribution": file_types
    }
    tree_json["full_statistics"] = full_stats
       
    # å¸¦è¯¦ç»†ä¿¡æ¯çš„å·¥ä½œåŒºæ ‘çŠ¶ç»“æ„ + å…¨é‡ç»Ÿè®¡ä¿¡æ¯
    stats_text = "\n\n" + "="*60 + "\nğŸ“Š å·¥ä½œåŒºå…¨é‡ç»Ÿè®¡ä¿¡æ¯ï¼ˆå«å­æ–‡ä»¶å¤¹ï¼‰\n" + "="*60
    stats_text += f"\nğŸ“ å·¥ä½œåŒºæ ¹ç›®å½•: {workspace_dir}"
    stats_text += f"\nğŸ“„ æ€»æ–‡ä»¶æ•°: {total_files}"
    stats_text += f"\nğŸ’¾ æ€»å¤§å°: {_format_file_size(total_size)} ({total_size:,} å­—èŠ‚)"
    stats_text += f"\nğŸ”§ æ²™ç®±æ¿€æ´»çŠ¶æ€: {'æ˜¯' if sandbox_active else 'å¦'}"
    stats_text += f"\nğŸ”’ ç¯å¢ƒæŒä¹…åŒ–: {'æ˜¯' if sandbox_active else 'å¦'}"
    
    if file_types:
        stats_text += "\n\nğŸ“ˆ æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:\n" + "-"*40
        for ext, info in sorted(file_types.items()):
            stats_text += f"\n  {ext:<15} {info['count']:>3} ä¸ªæ–‡ä»¶  {_format_file_size(info['size']):>10} ({info['size']:,} å­—èŠ‚)"
    
    tree_json = json.dumps(tree_json, ensure_ascii=False, indent=2)
    with open('file_struct.json', 'w', encoding='utf-8') as f:
                f.write(tree_json)
    with open('total_mes.txt', 'w', encoding='utf-8') as f:
        f.write(stats_text)

    return str(json.dumps(tree_json, ensure_ascii=False, indent=2))


@mcp.tool()
def load_json_and_find_file(target_path: str) -> None:
    """åŠ è½½ç”±get_workspace_structureå‡½æ•°ç”Ÿæˆçš„file_struct.jsonæ–‡ä»¶ï¼Œå¹¶ä»ä¸­æŸ¥æ‰¾æŒ‡å®šè·¯å¾„çš„åœ¨task_cache_diré¡¹ç›®ä¸­çš„æ–‡ä»¶ä¿¡æ¯
    æ³¨æ„ï¼Œæ­¤å·¥å…·åªèƒ½æŸ¥æ‰¾task_cache_diré¡¹ç›®ä¸­çš„æ–‡ä»¶ä¿¡æ¯ã€‚

    è¯»å–æ–‡ä»¶ç»“æ„JSONæ–‡ä»¶ï¼Œè§£æä¸ºå­—å…¸åè°ƒç”¨é€’å½’æŸ¥æ‰¾å‡½æ•°ï¼Œ
    å¹¶æ‰“å°æŸ¥æ‰¾ç»“æœï¼ˆæ‰¾åˆ°çš„æ–‡ä»¶ä¿¡æ¯æˆ–æœªæ‰¾åˆ°æç¤ºï¼‰
    
    Args:
        target_path: è¦æŸ¥æ‰¾çš„æ–‡ä»¶å®Œæ•´è·¯å¾„
    Return:
        æŸ¥è¯¢åˆ°ç›®æ ‡æ–‡ä»¶çš„ä¿¡æ¯
    """
    json_file_path = "file_struct.json"  

    try:
        with open(json_file_path, "r", encoding="utf-8") as f:
            json_content = f.read()
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°JSONæ–‡ä»¶ '{json_file_path}'ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        return
    except PermissionError:
        print(f"âŒ é”™è¯¯ï¼šæ²¡æœ‰æƒé™è¯»å–æ–‡ä»¶ '{json_file_path}'")
        return
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        return

    try:
        tree_data = json.loads(json_content)
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥ï¼š{str(e)}")
        return

    # æ‰§è¡ŒæŸ¥æ‰¾å¹¶å¤„ç†ç»“æœ
    file_info = recursively_find_file_in_json_tree(tree_data, target_path)
    if file_info:
        print("âœ… æ‰¾åˆ°æ–‡ä»¶ä¿¡æ¯ï¼š")
        return str(json.dumps(file_info, ensure_ascii=False, indent=2))
    else:
        print("âŒ æœªæ‰¾åˆ°è¯¥æ–‡ä»¶ï¼ˆæˆ–ç›®æ ‡è·¯å¾„æ˜¯ç›®å½•ï¼‰")

if __name__ == "__main__":
    mcp.run(transport="stdio")